{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8918541",
   "metadata": {},
   "source": [
    "## Link prediction with node2vec\n",
    "\n",
    "Goal is to predict whether a woman attended an event in the Southern Women bipartite network using node2vec embeddings.To do so I will load and verify the graph. Build positive and negative pairs. Do one full train test run. Then repeat the entire procedure ten times and average the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558db1b",
   "metadata": {},
   "source": [
    "Load libraries and set seeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47399d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea6a1a3",
   "metadata": {},
   "source": [
    "Read the network and confirm it loaded correctly. We're loading a bipartite network where yype 1 & 2 nodes = 18 women and yype 3 nodes = 14 events. Edges represents women attendance of events relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f506a53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph with 32 nodes and 89 edges\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "with open(\"data/southern_women.net\", 'r') as file:\n",
    "    # Skippinf the header\n",
    "    first_line = file.readline()\n",
    "    n_nodes = int(first_line.split()[1])\n",
    "    \n",
    "    # Read all nodes\n",
    "    for line in file:\n",
    "        if line.startswith(\"*\"):\n",
    "            break\n",
    "        else:\n",
    "            # Parsing node_id \"name\" type\n",
    "            parts = line.split(\"\\\"\")\n",
    "            node_id = parts[0].strip()\n",
    "            name = parts[1].strip()\n",
    "            node_type = int(parts[2].strip())\n",
    "            \n",
    "            G.add_node(node_id, name=name, type=node_type)\n",
    "    \n",
    "    # Read all edges\n",
    "    for line in file:\n",
    "        if line.startswith(\"*\"):\n",
    "            continue\n",
    "        edge = line.split()[:2]\n",
    "        if len(edge) == 2:\n",
    "            G.add_edge(edge[0], edge[1])\n",
    "\n",
    "print(f\"Loaded graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b30304",
   "metadata": {},
   "source": [
    "Example nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5650e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Node 1: Evelyn (type 1)\n",
      "  Node 2: Laura (type 1)\n",
      "  Node 3: Theresa (type 1)\n",
      "  Node 4: Brenda (type 1)\n",
      "  Node 5: Charlotte (type 1)\n",
      "  Node 6: Frances (type 1)\n",
      "  Node 7: Eleanor (type 1)\n",
      "  Node 8: Pearl (type 1)\n",
      "  Node 9: Ruth (type 1)\n",
      "  Node 10: Verne (type 2)\n"
     ]
    }
   ],
   "source": [
    "for i, (node, data) in enumerate(list(G.nodes(data=True))[:10]):\n",
    "    print(f\"  Node {node}: {data['name']} (type {data['type']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6176e4",
   "metadata": {},
   "source": [
    "Example edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a14171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evelyn → Event 1\n",
      "  Evelyn → Event 2\n",
      "  Evelyn → Event 3\n",
      "  Evelyn → Event 4\n",
      "  Evelyn → Event 5\n"
     ]
    }
   ],
   "source": [
    "for i, (u, v) in enumerate(list(G.edges())[:5]):\n",
    "    print(f\"  {G.nodes[u]['name']} → {G.nodes[v]['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc26c17",
   "metadata": {},
   "source": [
    "Lets separate nodes of women from nodes of events so to ensure negative examples only connect women-event and not women-women or events-events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cfaca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 women\n",
      "14 events\n"
     ]
    }
   ],
   "source": [
    "women = [n for n in G.nodes() if G.nodes[n]['type'] in [1, 2]]\n",
    "events = [n for n in G.nodes() if G.nodes[n]['type'] == 3]\n",
    "\n",
    "print(f\"{len(women)} women\")\n",
    "print(f\"{len(events)} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa098f0",
   "metadata": {},
   "source": [
    "Verified! There are 18 women and 14 events as expected. Now lets create positive (edge exist) examples and negative exxample (edge does not exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9eba176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 positive examples (existing edges)\n"
     ]
    }
   ],
   "source": [
    "positive_edges = list(G.edges())\n",
    "\n",
    "print(f\"{len(positive_edges)} positive examples (existing edges)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb73bd8",
   "metadata": {},
   "source": [
    "We need 89 negative examples too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf71fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 negative examples\n"
     ]
    }
   ],
   "source": [
    "negative_edges = []\n",
    "\n",
    "# Keep track of existing edges for faster lookup\n",
    "existing_edges = set(G.edges()) | set((v, u) for u, v in G.edges())\n",
    "\n",
    "#Sampling 89 negative pairs\n",
    "attempts = 0\n",
    "max_attempts = len(positive_edges) * 100  # Safety limit\n",
    "\n",
    "while len(negative_edges) < len(positive_edges) and attempts < max_attempts:\n",
    "    # Randomly pick a woman and an event\n",
    "    woman = random.choice(women)\n",
    "    event = random.choice(events)\n",
    "    \n",
    "    # Check if this pair is NOT connected\n",
    "    if (woman, event) not in existing_edges and (event, woman) not in existing_edges:\n",
    "        negative_edges.append((woman, event))\n",
    "    \n",
    "    attempts += 1\n",
    "\n",
    "print(f\"{len(negative_edges)} negative examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8366d6",
   "metadata": {},
   "source": [
    "Lets now make test and train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34f8f5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 142 edges\n",
      "Positive: 68 | Negative: 74\n",
      "Test set: 36 edges\n",
      "Positive: 21 | Negative: 15\n",
      "Original graph: 89 edges\n",
      "Training graph: 68 edges\n"
     ]
    }
   ],
   "source": [
    "all_edges = positive_edges + negative_edges\n",
    "all_labels = [1] * len(positive_edges) + [0] * len(negative_edges)\n",
    "\n",
    "\n",
    "# Shuffle all examples randomly\n",
    "indices = list(range(len(all_edges)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split 80/20\n",
    "split_point = int(0.8 * len(indices))\n",
    "train_idx = indices[:split_point]\n",
    "test_idx = indices[split_point:]\n",
    "\n",
    "# Create train and test sets\n",
    "train_edges = [all_edges[i] for i in train_idx]\n",
    "test_edges = [all_edges[i] for i in test_idx]\n",
    "train_labels = [all_labels[i] for i in train_idx]\n",
    "test_labels = [all_labels[i] for i in test_idx]\n",
    "\n",
    "print(f\"Training set: {len(train_edges)} edges\")\n",
    "print(f\"Positive: {sum(train_labels)} | Negative: {len(train_labels) - sum(train_labels)}\")\n",
    "print(f\"Test set: {len(test_edges)} edges\")\n",
    "print(f\"Positive: {sum(test_labels)} | Negative: {len(test_labels) - sum(test_labels)}\")\n",
    "\n",
    "# Remove positive test edges from graph to prevent data leakage\n",
    "test_positive_edges = [e for i, e in enumerate(test_edges) if test_labels[i] == 1]\n",
    "\n",
    "print(f\"Original graph: {G.number_of_edges()} edges\")\n",
    "G_train = G.copy()\n",
    "G_train.remove_edges_from(test_positive_edges)\n",
    "print(f\"Training graph: {G_train.number_of_edges()} edges\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b1400",
   "metadata": {},
   "source": [
    "Lets now generate Node2Vec embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d986ae38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5a3a7ba0a24859af3a5505e00fc8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate embeddings on the TRAINING graph \n",
    "node2vec = Node2Vec(\n",
    "    G_train,\n",
    "    dimensions=64,\n",
    "    walk_length=30,\n",
    "    num_walks=200,\n",
    "    p=1,\n",
    "    q=1,\n",
    "    workers=4,\n",
    "    seed=42,\n",
    "    quiet=False  # Show progress\n",
    ")\n",
    "\n",
    "# Fit the Word2Vec model\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4, seed=42)\n",
    "wv = model.wv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbd10e",
   "metadata": {},
   "source": [
    "Les now create edge features (vector of each women/event) from node embedding. I will use Hadamard product that is element wise multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73d6ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (142, 64)\n",
      "142 examples, each with 64 features\n",
      "Test features: (36, 64)\n",
      "36 examples, each with 64 features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to create edge features (Hadamard product)\n",
    "def create_edge_features(edges, wv):\n",
    "    features = []\n",
    "    for u, v in edges:\n",
    "        u_emb = wv[u]  # Get embedding for node u\n",
    "        v_emb = wv[v]  # Get embedding for node v\n",
    "        edge_emb = u_emb * v_emb  # Hadamard product (element-wise multiply)\n",
    "        features.append(edge_emb)\n",
    "    return np.array(features)\n",
    "\n",
    "# Create features for training and test sets\n",
    "\n",
    "X_train = create_edge_features(train_edges, wv)\n",
    "X_test = create_edge_features(test_edges, wv)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "print(f\"Training features: {X_train.shape}\")\n",
    "print(f\"{X_train.shape[0]} examples, each with {X_train.shape[1]} features\")\n",
    "print(f\"Test features: {X_test.shape}\")\n",
    "print(f\"{X_test.shape[0]} examples, each with {X_test.shape[1]} features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62645c11",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cac8045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52d7d1",
   "metadata": {},
   "source": [
    "Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cea3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]  # Probability of class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10546e",
   "metadata": {},
   "source": [
    "Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47c5c3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy:  0.5833  (58.3%)\n",
      "  ROC AUC:   0.7746\n",
      "  F1 Score:  0.4444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"  Accuracy:  {acc:.4f}  ({acc*100:.1f}%)\")\n",
    "print(f\"  ROC AUC:   {auc:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff188a",
   "metadata": {},
   "source": [
    "The accuracy seems low but ROC AUC of 0.775 is actually decent. It is not randonly classifying the links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bc7f9",
   "metadata": {},
   "source": [
    "Note: I have not done any hyperparamer tuning here because we do not have enough data validations set. Also it will be not practical because we are doing 10 random runs ahead. Lets run now LR 10 times. Rational is that we have small dataset so high variance in results.One run might get lucky (or unlucky) with the split. Running experiment 10 times will gives us confidence with our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a4202d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR Runs: 100%|██████████| 10/10 [01:05<00:00,  6.59s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Store results from all runs\n",
    "results_lr = []\n",
    "\n",
    "\n",
    "for run in tqdm(range(10), desc=\"LR Runs\"):\n",
    "    \n",
    "    # split data\n",
    "    indices = list(range(len(all_edges)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    split_point = int(0.8 * len(indices))\n",
    "    train_idx = indices[:split_point]\n",
    "    test_idx = indices[split_point:]\n",
    "    \n",
    "    train_edges_run = [all_edges[i] for i in train_idx]\n",
    "    test_edges_run = [all_edges[i] for i in test_idx]\n",
    "    train_labels_run = [all_labels[i] for i in train_idx]\n",
    "    test_labels_run = [all_labels[i] for i in test_idx]\n",
    "    \n",
    "    # create training graph\n",
    "    test_positive = [e for i, e in enumerate(test_edges_run) if test_labels_run[i] == 1]\n",
    "    G_train_run = G.copy()\n",
    "    G_train_run.remove_edges_from(test_positive)\n",
    "    \n",
    "    # generate node2vec embeddings\n",
    "    node2vec = Node2Vec(\n",
    "        G_train_run,\n",
    "        dimensions=64,\n",
    "        walk_length=30,\n",
    "        num_walks=200,\n",
    "        p=1, q=1,\n",
    "        workers=4,\n",
    "        seed=42 + run,  # Different seed for each run\n",
    "        quiet=True\n",
    "    )\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4, seed=42 + run)\n",
    "    wv = model.wv\n",
    "    \n",
    "    # create edge features\n",
    "    X_train_run = create_edge_features(train_edges_run, wv)\n",
    "    X_test_run = create_edge_features(test_edges_run, wv)\n",
    "    y_train_run = np.array(train_labels_run)\n",
    "    y_test_run = np.array(test_labels_run)\n",
    "    \n",
    "    # train classifier\n",
    "    clf_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf_lr.fit(X_train_run, y_train_run)\n",
    "    \n",
    "    # evaluate\n",
    "    y_pred = clf_lr.predict(X_test_run)\n",
    "    y_proba = clf_lr.predict_proba(X_test_run)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y_test_run, y_pred)\n",
    "    auc = roc_auc_score(y_test_run, y_proba)\n",
    "    f1 = f1_score(y_test_run, y_pred)\n",
    "    \n",
    "    results_lr.append({\n",
    "        'accuracy': acc,\n",
    "        'auc': auc,\n",
    "        'f1': f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19534a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metric       Mean         Std Dev      Range               \n",
      "--------------------------------------------------\n",
      "Accuracy     0.5917      0.1224      [0.2778, 0.7500]\n",
      "ROC AUC      0.7513      0.0586      [0.6571, 0.8297]\n",
      "F1 Score     0.5398      0.1840      [0.0714, 0.7273]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# average and std dev of acc, auc, f1\n",
    "\n",
    "acc_mean = np.mean([r['accuracy'] for r in results_lr])\n",
    "acc_std = np.std([r['accuracy'] for r in results_lr])\n",
    "auc_mean = np.mean([r['auc'] for r in results_lr])\n",
    "auc_std = np.std([r['auc'] for r in results_lr])\n",
    "f1_mean = np.mean([r['f1'] for r in results_lr])\n",
    "f1_std = np.std([r['f1'] for r in results_lr])\n",
    "\n",
    "print(f\"\\n{'Metric':<12} {'Mean':<12} {'Std Dev':<12} {'Range':<20}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Accuracy':<12} {acc_mean:.4f}      {acc_std:.4f}      [{min(r['accuracy'] for r in results_lr):.4f}, {max(r['accuracy'] for r in results_lr):.4f}]\")\n",
    "print(f\"{'ROC AUC':<12} {auc_mean:.4f}      {auc_std:.4f}      [{min(r['auc'] for r in results_lr):.4f}, {max(r['auc'] for r in results_lr):.4f}]\")\n",
    "print(f\"{'F1 Score':<12} {f1_mean:.4f}      {f1_std:.4f}      [{min(r['f1'] for r in results_lr):.4f}, {max(r['f1'] for r in results_lr):.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51362809",
   "metadata": {},
   "source": [
    "Acc of 0.59 is moderate but variance is high. On other hand AUC is pretty good means model ranks the links well. F1 is 0.54 which is reasonable for smaller datasets. High std dev of ACC, F1 shows thats sentivity due to small data. So AUC is more of stable and infomative than ACC here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f621c38",
   "metadata": {},
   "source": [
    "Lets improve our classifier by building random forest model and running 10 experiments and finally averaging the metrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8891079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RF Runs: 100%|██████████| 10/10 [01:43<00:00, 10.35s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "results_rf = []\n",
    "\n",
    "\n",
    "for run in tqdm(range(10), desc=\"RF Runs\"):\n",
    "    \n",
    "    # split data\n",
    "    indices = list(range(len(all_edges)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    split_point = int(0.8 * len(indices))\n",
    "    train_idx = indices[:split_point]\n",
    "    test_idx = indices[split_point:]\n",
    "    \n",
    "    train_edges_run = [all_edges[i] for i in train_idx]\n",
    "    test_edges_run = [all_edges[i] for i in test_idx]\n",
    "    train_labels_run = [all_labels[i] for i in train_idx]\n",
    "    test_labels_run = [all_labels[i] for i in test_idx]\n",
    "    \n",
    "    # create training graph\n",
    "    test_positive = [e for i, e in enumerate(test_edges_run) if test_labels_run[i] == 1]\n",
    "    G_train_run = G.copy()\n",
    "    G_train_run.remove_edges_from(test_positive)\n",
    "    \n",
    "    # generate node2vec embeddings\n",
    "    node2vec = Node2Vec(\n",
    "        G_train_run,\n",
    "        dimensions=64,\n",
    "        walk_length=30,\n",
    "        num_walks=200,\n",
    "        p=1, q=1,\n",
    "        workers=4,\n",
    "        seed=42 + run,\n",
    "        quiet=True\n",
    "    )\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4, seed=42 + run)\n",
    "    wv = model.wv\n",
    "    \n",
    "    # create edge features\n",
    "    X_train_run = create_edge_features(train_edges_run, wv)\n",
    "    X_test_run = create_edge_features(test_edges_run, wv)\n",
    "    y_train_run = np.array(train_labels_run)\n",
    "    y_test_run = np.array(test_labels_run)\n",
    "    \n",
    "    # train RF\n",
    "    clf_rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1  # Use all CPU cores\n",
    "    )\n",
    "    clf_rf.fit(X_train_run, y_train_run)\n",
    "    \n",
    "    # evaluate\n",
    "    y_pred = clf_rf.predict(X_test_run)\n",
    "    y_proba = clf_rf.predict_proba(X_test_run)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y_test_run, y_pred)\n",
    "    auc = roc_auc_score(y_test_run, y_proba)\n",
    "    f1 = f1_score(y_test_run, y_pred)\n",
    "    \n",
    "    results_rf.append({\n",
    "        'accuracy': acc,\n",
    "        'auc': auc,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40aaba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metric       Mean         Std Dev      Range               \n",
      "--------------------------------------------------\n",
      "Accuracy     0.7556      0.0984      [0.6111, 0.9444]\n",
      "ROC AUC      0.9155      0.0577      [0.8359, 0.9938]\n",
      "F1 Score     0.7159      0.1096      [0.5333, 0.9286]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "acc_mean_rf = np.mean([r['accuracy'] for r in results_rf])\n",
    "acc_std_rf = np.std([r['accuracy'] for r in results_rf])\n",
    "auc_mean_rf = np.mean([r['auc'] for r in results_rf])\n",
    "auc_std_rf = np.std([r['auc'] for r in results_rf])\n",
    "f1_mean_rf = np.mean([r['f1'] for r in results_rf])\n",
    "f1_std_rf = np.std([r['f1'] for r in results_rf])\n",
    "\n",
    "print(f\"\\n{'Metric':<12} {'Mean':<12} {'Std Dev':<12} {'Range':<20}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Accuracy':<12} {acc_mean_rf:.4f}      {acc_std_rf:.4f}      [{min(r['accuracy'] for r in results_rf):.4f}, {max(r['accuracy'] for r in results_rf):.4f}]\")\n",
    "print(f\"{'ROC AUC':<12} {auc_mean_rf:.4f}      {auc_std_rf:.4f}      [{min(r['auc'] for r in results_rf):.4f}, {max(r['auc'] for r in results_rf):.4f}]\")\n",
    "print(f\"{'F1 Score':<12} {f1_mean_rf:.4f}      {f1_std_rf:.4f}      [{min(r['f1'] for r in results_rf):.4f}, {max(r['f1'] for r in results_rf):.4f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3ed73",
   "metadata": {},
   "source": [
    "Clearly the ACC improved from 0.59 to 0.75. AUC and F1 score also improved by big leap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaeca66",
   "metadata": {},
   "source": [
    "**Final commentary:** So basically I framed the problem as a binary classification task on woman–event pairs. Positives were the 89 observed attendance links while negatives were 89 uniformly sampled missing woman–event pair. For each run I did a stratified 80–20 split, removed the positive test edges from the graph to avoid leakage, learned node2vec embeddings on the pruned graph with dim=64, walk length=30, 200 walks per node, p=q=1 and represented a pair by the Hadamard product of its two node vectors. I repeated the entire pipeline 10 times (fresh negatives and split each time). \n",
    "\n",
    "Random Forest clearly outperformed Logistic Regression on these embeddings. Averaged over 10 runs, RF reached about 0.76 accuracy, 0.92 ROC-AUC, and 0.72 F1, compared with LR at ~0.59 accuracy, 0.75 AUC, and 0.54 F1. The gap suggests non-linear interactions between the two node embeddings matter. An ensemble of trees captures these patterns better than a linear boundary. The high AUC indicates the model ranks true links above non-links reliably, while F1 shows balanced precision and recall on the balanced test set. Some variance remains due to the small graph and the stochastic nature of walks and sampling, which is why averaging across 10 independent runs is important.\n",
    "\n",
    "Lastly rational for choice of using the hadamard product is that it is a simple, well-supported operator for link prediction with node2vec and directly models feature interactions between the two endpoints. For example if both have high value edge feature will be high and if they disagree edge feature will be lower. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
